# 面经预热Day5

美团-后端研发工程师-一面-0912

开场，自我介绍，闲聊，如何看待互联网寒冬，如何看待35岁危机，生涯规划等等

聊项目，实习经历，树洞、KV引擎牵扯到数据库

## 数据库慢查询问题如何优化

数据库慢查询是指在执行查询操作时，数据库返回结果的速度较慢，导致系统响应缓慢或性能下降的情况。

要优化数据库慢查询，可以从以下几个方面入手：

1. 索引优化：合理地创建索引可以加快查询速度。对于经常被查询的字段，可以考虑创建索引。但是过多的索引也会降低写操作的性能，所以需要权衡。

2. 查询语句优化：通过优化查询语句来提高查询效率。例如，避免使用全表扫描，使用合适的条件和关键字，避免不必要的排序和连接操作。

3. 数据库表设计优化：合理地设计数据库表结构可以提高查询性能。例如，将频繁查询的字段放在一个表中，减少表的连接操作。

4. 数据库参数调整：根据具体的数据库系统，调整相关的参数，以提高查询性能。例如，增加内存缓存，调整并发连接数等。

5. 数据库分区：对于大型数据库，可以考虑将表分成多个分区，以提高查询性能和管理效率。

6. 查询缓存：使用数据库自带的查询缓存功能，可以缓存查询结果，在下次查询相同数据时直接返回缓存结果，减少数据库查询的开销。

7. 数据库服务器硬件升级：如果数据库服务器性能较低，可以考虑升级硬件，例如增加内存、CPU等，以提高查询性能。

## 数据库索引

数据库索引是一种数据结构，用于加快数据库查询操作的速度。它类似于书籍的目录，可以快速定位到特定数据的位置，而不需要全表扫描。

数据库索引分为多种类型，常见的有B树索引和哈希索引。

1. B树索引：B树索引是最常见的索引类型，适用于范围查询和排序。它基于平衡树的数据结构，每个节点可以存储多个键值对。B树索引的特点是有序存储，可以快速定位到目标数据的位置。常见的B树索引包括B+树和B树。

2. 哈希索引：哈希索引适用于等值查询，例如根据主键进行查询。它使用哈希算法将键值映射到索引位置，然后通过索引位置直接访问数据。哈希索引的特点是查询速度非常快，但不支持范围查询和排序。

在使用数据库索引时，需要注意以下几点：

1. 选择合适的列进行索引：通常选择经常被查询的列进行索引，例如主键、外键和经常出现在WHERE子句中的列。

2. 避免过多的索引：创建过多的索引会导致插入和更新操作变慢，并占用更多的存储空间。需要权衡查询性能和写操作性能，避免过度索引。

3. 联合索引：当多个列经常同时出现在查询条件中时，可以考虑创建联合索引。联合索引可以提高查询效率，避免多次索引查找。

4. 定期维护索引：随着数据的增加和修改，索引会变得不均衡，需要定期进行索引的重新组织和优化，保持索引的高效性。

5. 使用覆盖索引：覆盖索引是指在索引中包含了查询所需的所有列。通过使用覆盖索引，可以减少对数据页的访问，提高查询性能。

## B+树及其检索效率

B+树是一种常用的索引数据结构，它在数据库中被广泛应用于提高检索效率。B+树的检索效率非常高，其时间复杂度为O(log n)，其中n是数据的总数。

B+树的检索效率高主要有以下几个原因：

1. 平衡性：B+树是一种平衡树，每个节点的子树高度相等或相差不超过1，这保证了在最坏情况下的检索效率也能维持在O(log n)的级别。
2. 多路搜索：B+树的每个节点可以存储多个键值对，而不仅仅是一个键值对。这样每次搜索时可以一次读取多个键值对，减少了磁盘I/O次数，提高了检索效率。
3. 顺序访问性：B+树的节点按照键值的大小顺序进行存储，使得范围查询和顺序访问非常高效。可以通过一次磁盘I/O读取连续的键值对，减少了磁盘的随机读写操作。
4. 数据集中性：B+树的叶子节点保存了所有的数据，而非叶子节点只保存索引信息。这样相邻的数据会被存储在相邻的叶子节点中，提高了数据的聚簇性，减少了磁盘的随机访问。

## 跳表及其时间复杂度

跳表（Skip List）是一种基于链表的数据结构，它通过添加多级索引来加快数据的查找速度。跳表可以看作是一种平衡树的变种，相比于平衡树，它的实现更加简单，并且在实际应用中具有较高的效率。

跳表中的每个节点包含一个值和多个指针，指针用于连接同一层级的下一个节点，以及连接下一层级的节点。跳表的最底层是普通链表，每个节点都有指向下一个节点的指针。而上方的层级是通过一定的概率选择建立的，每一层级的节点数量逐渐减少，形成了一种“跳跃”的效果。

跳表的时间复杂度如下：

- 查找操作的时间复杂度为O(log n)，其中n为跳表中节点的数量。由于跳表的每一层级数量逐渐减少，查找操作可以通过跳跃层级来快速定位到目标节点，然后在目标层级上进行线性查找。

- 插入和删除操作的时间复杂度也为O(log n)。与查找操作类似，插入和删除操作需要先定位到目标节点，然后在目标层级上进行插入或删除操作。由于涉及到更新索引的调整，因此时间复杂度为O(log n)。

跳表的优势在于实现简单，并且在某些场景下能够提供接近平衡树的查询性能。但它也有一些限制，例如需要额外的空间来存储索引，以及对于有序性的维护相对复杂等。因此，在选择数据结构时，需要根据具体的应用场景和需求来权衡使用跳表的利弊。

## 讲讲跳表查询的过程路径

跳表查询的过程路径可以通过以下步骤来说明：

1. 从跳表的头节点开始，向右移动到当前层级的下一个节点。
2. 比较当前节点的值和目标值的大小。
   - 如果当前节点的值等于目标值，说明找到了目标节点，结束查询。
   - 如果当前节点的值大于目标值，说明目标节点位于当前节点的前一个节点。
     - 如果当前节点是当前层级的第一个节点，说明目标值不存在于当前层级，需要向下一层级进行查找。
     - 如果当前节点不是当前层级的第一个节点，需要跳到当前层级的前一个节点，然后向下一层级进行查找。
   - 如果当前节点的值小于目标值，继续向右移动到下一个节点，重复上述步骤。
3. 重复上述步骤，直到找到目标节点或者到达跳表的最后一层级。

在每一层级的查询过程中，通过比较节点的值和目标值的大小，可以确定是继续向右移动还是跳跃到下一层级进行查找。通过这种方式，可以快速定位到目标节点，然后在目标层级上进行线性查找。

需要注意的是，跳表的每一层级都是有序的，所以在进行查找时，可以通过比较节点的值和目标值的大小来确定查找方向。这种索引结构提供了快速定位的能力，从而减少了查找的时间复杂度。

在实际应用中，跳表的层级数量和每层级节点的数量可以根据需求进行调整，以平衡查询性能和空间占用。同时，插入和删除操作也需要维护索引结构，以保持跳表的平衡性。

## 覆盖索引

覆盖索引是指索引包含了查询所需的所有列，而不仅仅是用于查找的键列。通过使用覆盖索引，可以减少磁盘I/O操作，提高查询性能。

当执行查询时，如果所需的列都包含在索引中，数据库引擎可以直接从索引中获取数据，而无需访问主表的数据页。这样可以减少磁盘I/O次数，提升查询效率。相比于从主表中读取数据，从索引中读取数据的成本通常更低。

要创建覆盖索引，你需要考虑以下几点：

1. 确定需要包含在索引中的列：分析查询语句，确定查询语句需要的列，并将其包含在索引中。通常，这些列包括查询的筛选条件和需要返回的列。

2. 确定索引的顺序：索引的顺序应该与查询语句的顺序匹配，以便更好地利用索引。

3. 注意索引的大小：覆盖索引可能比非覆盖索引更大，因为它包含了更多的列。需要权衡存储空间和查询性能之间的平衡。

需要注意的是，并非所有的查询都适合使用覆盖索引。当查询需要大量的列或者查询结果集较大时，使用覆盖索引可能会增加索引的大小，增加了查询的开销。此外，频繁更新的表可能会因为维护覆盖索引而引起性能下降。

因此，在创建覆盖索引时，需要综合考虑查询的需求、数据的更新频率以及存储空间的限制，权衡利弊。

## 聚簇索引

聚簇索引是一种索引方式，它通过将数据行存储在与索引相同的顺序中来改善查询性能。在聚簇索引中，表的数据行按照索引键的顺序物理地存储在磁盘上。

当使用聚簇索引时，数据库引擎会根据聚簇索引的键值对来组织和排序数据行。这意味着具有相近键值的数据行会在物理上彼此相邻。这种存储方式可以提高范围查询和顺序访问的性能，因为相关的数据行通常存储在相邻的磁盘块中，减少了磁盘I/O操作的次数。

与聚簇索引相对的是非聚簇索引（也称为辅助索引），它是基于数据行的物理存储顺序无关的索引。在非聚簇索引中，索引键值对指向实际数据行的位置，而数据行可以按照任意顺序存储。

聚簇索引的优点包括：

1. 范围查询和顺序访问性能更好：由于相关的数据行存储在相邻的磁盘块中，聚簇索引可以减少磁盘I/O操作的次数，提高查询性能。

2. 减少磁盘空间的使用：由于数据行按照索引键的顺序存储，相邻的数据行通常具有相似的值。这种存储方式可以减少重复数据的存储，节省磁盘空间。

然而，聚簇索引也有一些限制和注意事项：

1. 每个表只能有一个聚簇索引：由于数据行的物理存储顺序是由聚簇索引决定的，所以每个表只能有一个聚簇索引。

2. 聚簇索引的更新开销较大：当插入、更新或删除数据时，聚簇索引需要重新组织和调整数据行的物理存储顺序，可能会引起性能下降。

3. 不适合频繁的插入和更新操作：由于聚簇索引的更新开销较大，对于频繁进行插入和更新操作的表，可能会影响性能。

在设计数据库表时，需要根据具体的查询需求和数据访问模式来选择使用聚簇索引还是非聚簇索引。聚簇索引适用于范围查询和顺序访问较多的场景，而非聚簇索引适用于频繁进行插入和更新操作的场景。

## 非主键查询

非主键查询是指根据非主键字段（即不是表的主键）进行查询操作。在数据库中，主键是用于唯一标识表中每一条记录的字段。

非主键查询的过程如下：

1. 首先，数据库会检查是否有适当的索引可用于非主键字段。如果有相应的索引，数据库会使用该索引来加速查询操作。否则，将进行全表扫描，逐条检查非主键字段的值。

2. 如果有适当的索引，数据库会根据查询条件中的非主键字段值，通过索引定位到符合条件的记录的位置。

3. 对于单个值查询，数据库可以直接通过索引定位到该值所在的位置。对于范围查询，数据库会根据索引的有序性，在索引中找到满足条件的范围，并定位到对应的记录位置。

4. 一旦数据库定位到相应的记录位置，它会读取记录的数据并返回给查询的结果。

需要注意的是，非主键查询可能会导致较慢的查询性能，特别是在没有相应的索引或索引不适用的情况下。全表扫描需要逐条检查每一条记录，这会导致查询时间较长。

为了优化非主键查询的性能，可以考虑以下几点：

- 创建适当的索引：根据查询的字段和查询的频率，创建合适的索引可以大大提高查询的效率。

- 使用覆盖索引：覆盖索引是指索引中包含了查询所需的所有字段，这样数据库可以直接从索引中获取数据，而无需进一步读取表中的数据，从而提高查询性能。

- 调整查询语句：优化查询语句的编写，使用合适的查询条件和索引，避免不必要的计算和过滤操作，提高查询效率。

- 数据库性能优化：除了索引和查询语句的优化外，还可以通过调整数据库的配置参数、硬件升级等方式来提高非主键查询的性能。

综上所述，非主键查询的过程涉及到索引的使用和定位，以及数据的读取和返回。通过合理使用索引、优化查询语句和数据库性能优化，可以提高非主键查询的效率。

## 数据库事务

SQL的事务（Transaction）是一组操作的逻辑单元，这些操作要么全部成功执行，要么全部回滚（Rollback），以保证数据库的一致性和完整性。

事务具有以下四个特性（ACID）：

1. 原子性（Atomicity）：事务中的所有操作要么全部执行成功，要么全部回滚。如果事务中的任何一个操作失败，则整个事务都会被回滚到最初的状态，不会对数据库产生任何影响。

2. 一致性（Consistency）：事务在执行前和执行后都必须保持数据库的一致性。这意味着事务中的所有操作都必须遵循数据库的约束和规则，以确保数据的完整性。

3. 隔离性（Isolation）：事务的执行是相互隔离的，即一个事务的操作对其他事务是不可见的。隔离性可以防止并发执行事务时产生一些不一致的结果。

4. 持久性（Durability）：一旦事务提交成功，其对数据库的修改将永久保存，即使在系统故障或重启后也不会丢失。

在SQL中，使用以下语句来控制事务的开始、提交和回滚：

1. BEGIN TRANSACTION 或 START TRANSACTION：开始一个新的事务。

2. COMMIT：提交事务，将事务中的所有操作永久保存到数据库。

3. ROLLBACK：回滚事务，撤销事务中的所有操作，恢复到事务开始之前的状态。

事务的使用可以确保数据的一致性和完整性，同时提供了并发控制和故障恢复的能力。在需要执行多个操作并保持数据的一致性时，可以使用事务来进行操作。

## 数据库隔离性的隔离级别

SQL中定义了多个事务隔离级别，用来控制事务之间的隔离程度。这些隔离级别包括：

1. 读未提交（Read Uncommitted）：最低的隔离级别，允许一个事务读取另一个事务尚未提交的数据。这种隔离级别存在脏读（Dirty Read）的问题，即一个事务读取到了另一个事务未提交的数据。

2. 读已提交（Read Committed）：允许一个事务读取并发事务已经提交的数据。这种隔离级别避免了脏读，但可能存在不可重复读（Non-repeatable Read）的问题，即同一个事务内多次读取同一行数据，但结果不一致。

3. 可重复读（Repeatable Read）：保证在事务执行期间，同一个事务多次读取同一行数据的结果是一致的。这种隔离级别避免了脏读和不可重复读，但可能存在幻读（Phantom Read）的问题，即一个事务在前后两次查询同一范围的数据时，结果集不一致。

4. 串行化（Serializable）：最高的隔离级别，强制事务串行执行，避免了脏读、不可重复读和幻读的问题。串行化隔离级别会对数据库的并发性能产生较大的影响，因为它禁止了并发执行。

不同的隔离级别提供了不同的事务隔离性和并发性能。选择合适的隔离级别需要根据具体的应用场景和需求来决定。一般来说，隔离级别越高，数据的一致性越好，但并发性能也越差。

在SQL中，可以使用以下语句来设置事务的隔离级别：

```
SET TRANSACTION ISOLATION LEVEL <隔离级别>;
```

其中，`<隔离级别>`可以是 READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ 或 SERIALIZABLE。默认的隔离级别通常是数据库系统特定的，可以通过设置来修改默认的隔离级别。

## EXPLAIN语句

在SQL中，EXPLAIN语句用于分析和解释查询语句的执行计划。执行计划是数据库引擎根据查询语句和数据库的结构，确定最有效的查询执行方式的详细说明。

EXPLAIN语句的语法通常是：

```
EXPLAIN <查询语句>;
```

执行EXPLAIN语句后，数据库引擎会返回一个描述查询执行计划的结果集，包含了查询的各个步骤和操作的详细信息。这些信息可以帮助开发人员和数据库管理员优化查询性能。

执行计划结果集中的字段通常包括：

1. id：每个操作步骤的唯一标识符，可以通过id字段来确定操作的顺序。

2. select_type：操作的类型，例如SIMPLE（简单查询）、SUBQUERY（子查询）等。

3. table：操作涉及的表名。

4. type：访问表的方式，例如ALL（全表扫描）、INDEX（使用索引）等。

5. possible_keys：可能使用的索引。

6. key：实际使用的索引。

7. key_len：索引使用的长度。

8. ref：索引的比较列。

9. rows：估计的返回行数。

10. Extra：附加的操作信息，例如Using Where（使用了WHERE条件）、Using Index（使用了索引）等。

通过分析执行计划，可以确定查询中存在的性能瓶颈和优化的可能性。例如，可以根据执行计划来判断是否需要创建新的索引、是否需要重写查询语句、是否需要调整表结构等。

需要注意的是，执行计划是根据数据库的统计信息和查询语句的结构生成的，它只是一个估计值，实际执行情况可能会有所不同。因此，在优化查询性能时，需要综合考虑执行计划和实际执行情况。

## MYSQL主从架构

MySQL主从架构是一种常见的数据库架构，它通过将数据库复制到多个服务器上，从而实现数据的冗余备份、读写分离和提高系统的可用性。主从架构包括一个主数据库（Master）和一个或多个从数据库（Slave）。

实现MySQL主从架构的方式如下：

1. 配置主数据库：首先，在主数据库上进行相应的配置。需要在主数据库的配置文件中启用二进制日志（binary log），这是主数据库用于记录所有的数据库操作语句的文件。同时，还需要为主数据库创建一个用于复制的账户，并给予复制账户相应的权限。

2. 配置从数据库：在从数据库上进行配置。需要在从数据库的配置文件中启用复制功能。配置文件中需要指定主数据库的连接信息，包括主数据库的IP地址、端口号、复制账户的用户名和密码等。

3. 启动主从复制：在主数据库上，通过执行`FLUSH TABLES WITH READ LOCK`命令来获取当前数据库的状态，并使其处于只读状态。然后，通过执行`SHOW MASTER STATUS`命令来获取二进制日志文件名和位置。

4. 设置从数据库复制参数：在从数据库上，通过执行`CHANGE MASTER TO`命令来设置复制的参数。需要指定主数据库的连接信息，包括主数据库的IP地址、端口号、二进制日志文件名和位置。

5. 启动从数据库复制：在从数据库上，通过执行`START SLAVE`命令来启动从数据库的复制进程。从数据库会连接到主数据库，并开始从主数据库的二进制日志中读取日志，并将其应用到从数据库。

6. 监控复制状态：可以通过执行`SHOW SLAVE STATUS`命令来查看从数据库的复制状态。在返回的结果中，可以查看复制进程的状态、延迟、错误等信息。

通过以上步骤，就可以实现MySQL主从架构。主数据库负责处理写操作，并将写操作的日志记录到二进制日志中，从数据库则负责读操作，并通过复制进程从主数据库的二进制日志中读取并应用写操作。这样，就实现了数据的冗余备份和读写分离，提高了系统的可用性和性能。

需要注意的是，MySQL主从复制是异步的，从数据库的数据可能会有一定的延迟。此外，主从复制还需要进行监控和维护，以确保复制的准确性和稳定性。

## TCP如何实现可靠传输

TCP实现可靠传输的主要机制包括序列号、确认应答、超时重传、拥塞控制等。

1. 序列号（Sequence Number）：
   TCP将每个字节的数据进行编号，发送方使用序列号标识发送的数据字节的顺序。接收方通过序列号来确认已接收的数据，并按正确的顺序进行重组。

2. 确认应答（Acknowledgment）：
   接收方在收到数据后，会发送一个确认应答给发送方。确认应答中包含了已成功接收数据的最新的序列号。发送方根据接收到的确认应答确定哪些数据已经成功传输。

3. 超时重传（Timeout Retransmission）：
   发送方在发送数据后会启动一个定时器。如果在一定时间内没有收到确认应答，发送方会认为数据丢失，触发超时重传机制，重新发送未确认的数据。

4. 滑动窗口（Sliding Window）：
   TCP使用滑动窗口机制来控制流量和提高传输效率。发送方和接收方都维护一个窗口，窗口的大小取决于网络状况和接收方的处理能力。发送方根据接收方窗口的大小来发送数据，接收方根据自己的处理能力和可接受的窗口大小来确认数据。

5. 拥塞控制（Congestion Control）：
   TCP通过拥塞控制机制来避免网络拥塞。发送方根据网络的拥塞程度来调整发送的速率。当网络出现拥塞时，发送方会减少发送的数据量，以降低网络负载。

通过这些机制，TCP能够保证数据的可靠传输。序列号和确认应答机制确保数据的顺序和完整性，超时重传机制处理丢失的数据，滑动窗口机制控制流量和提高效率，拥塞控制机制避免网络拥塞。这些机制结合起来，使得TCP成为一种可靠的传输协议。

## 拥塞控制控制的是哪里的拥塞？

拥塞控制是TCP协议中的一种机制，用于控制网络中的拥塞。它的作用是通过调整发送方的数据发送速率，以避免网络拥塞和保持网络的稳定性。

拥塞控制的目标是在网络中维持一个合理的传输负载，避免过多的数据流量导致网络拥塞、丢包和延迟增加。如果网络出现拥塞，数据包可能会因为网络资源不足而丢失，甚至导致整个网络的崩溃。

拥塞控制的主要机制包括：

1. 慢启动（Slow Start）：在连接建立时，发送方以较慢的速率发送数据，逐渐增加发送窗口的大小，以避免一开始就发送过多的数据导致拥塞。

2. 拥塞避免（Congestion Avoidance）：在慢启动阶段结束后，发送方会以一定的速率逐渐增加发送窗口的大小，但增加的速率会缓慢下降，以避免过快增加导致拥塞。

3. 快重传（Fast Retransmit）：如果发送方检测到丢失的数据包，而且接收方已经确认了连续的数据包，发送方会立即进行重传，而不是等待超时重传。

4. 快恢复（Fast Recovery）：在进行快重传后，发送方会减少发送窗口的大小，并使用拥塞避免算法继续发送数据，以快速恢复到正常的发送速率。

通过这些机制，TCP可以根据网络的拥塞程度来动态调整数据的发送速率，避免网络拥塞发生，并保持网络的稳定性和公平性。拥塞控制的目的是在网络中平衡数据的发送和网络资源的利用，以提供可靠的数据传输服务。

## 5开头状态码

5开头的状态码是HTTP协议中表示服务器端错误的状态码。当服务器在处理客户端请求时出现错误或无法完成请求时，会返回5开头的状态码来指示错误的类型。

以下是常见的5开头状态码：

1. 500 Internal Server Error（内部服务器错误）：
   表示服务器在处理请求时发生了未知的内部错误，导致无法完成请求。

2. 501 Not Implemented（未实现）：
   表示服务器不支持或未实现请求的功能或方法。

3. 502 Bad Gateway（错误的网关）：
   表示服务器作为网关或代理时从上游服务器接收到无效的响应。

4. 503 Service Unavailable（服务不可用）：
   表示服务器暂时无法处理请求，通常是由于服务器过载或维护导致的。

5. 504 Gateway Timeout（网关超时）：
   表示服务器作为网关或代理在等待上游服务器响应时超时。

这些状态码都表示服务器端错误，客户端在收到这些状态码后应该根据具体情况采取相应的处理措施，例如重试请求、联系服务器管理员等。

## TopK问题

```Python
from collections import Counter

def topKFrequent(nums, k):
    # 使用Counter统计数组中各元素的频率
    counter = Counter(nums)
    
    # 按照频率进行排序，取出前k个高频元素
    top_k = counter.most_common(k)
    
    # 返回前k个高频元素的值
    return [num for num, _ in top_k]

nums = [1, 1, 1, 2, 2, 3]
k = 2
result = topKFrequent(nums, k)
print(result)  # 输出 [1, 2]

```

这段代码的思路如下：

1. 首先，我们使用 `Counter` 类来统计数组 `nums` 中各元素的频率。`Counter` 是一个 Python 内置的计数器工具，它可以帮助我们快速统计一个可迭代对象中各元素的个数。

2. 接下来，我们使用 `most_common` 方法对统计结果进行排序。`most_common` 方法会返回一个按照频率降序排列的元素列表，每个元素是一个二元组 `(element, count)`，其中 `element` 是数组中的元素，`count` 是该元素的频率。

3. 我们取出排序结果中的前 `k` 个元素，这样就得到了出现频率前 `k` 高的元素。

4. 最后，我们只需要返回这些元素的值即可。这里我们使用了列表推导式来提取出元素的值，将它们放入一个新的列表中并返回。

总结起来，这段代码的思路就是先统计数组中各元素的频率，然后按照频率排序，最后取出前 `k` 个高频元素的值并返回。通过使用 `Counter` 类和列表推导式，我们可以很方便地实现这个功能。